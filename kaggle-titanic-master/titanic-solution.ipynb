{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6a09d4fb-60c5-4f45-b844-8c788a50c543",
    "_uuid": "8e892e637f005dd61ec7dcb95865e52f3de2a77f"
   },
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "### Predict survival on the Titanic\n",
    "- Defining the problem statement\n",
    "- Collecting the data\n",
    "- Exploratory data analysis\n",
    "- Feature engineering\n",
    "- Modelling\n",
    "- Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4af5e83d-7fd8-4a61-bf26-9583cb6d3476",
    "_uuid": "65d04d276a8983f62a49261f6e94a02b281dbcc9"
   },
   "source": [
    "## 1. Defining the problem statement\n",
    "Complete the analysis of what sorts of people were likely to survive.  \n",
    "In particular, we ask you to apply the tools of machine learning to predict which passengers survived the Titanic tragedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://static1.squarespace.com/static/5006453fe4b09ef2252ba068/5095eabce4b06cb305058603/5095eabce4b02d37bef4c24c/1352002236895/100_anniversary_titanic_sinking_by_esai8mellows-d4xbme8.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 문제 정의\n",
    "\n",
    "# jupyter notebook에서 사진을 표시하기 위해 IPytho.display의 Image 임포트\n",
    "from IPython.display import Image\n",
    "\n",
    "# 이미지 표시\n",
    "Image(url= \"https://static1.squarespace.com/static/5006453fe4b09ef2252ba068/5095eabce4b06cb305058603/5095eabce4b02d37bef4c24c/1352002236895/100_anniversary_titanic_sinking_by_esai8mellows-d4xbme8.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3f529075-7f9b-40ff-a79a-f3a11a7d8cbe",
    "_uuid": "64ca0f815766e3e8074b0e04f53947930cb061aa"
   },
   "source": [
    "## 2. Collecting the data\n",
    "\n",
    "training data set and testing data set are given by Kaggle\n",
    "you can download from kaggle directly [kaggle](https://www.kaggle.com/c/titanic/data)  \n",
    "\n",
    "### load train, test dataset using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e58a3f06-4c2a-4b87-90de-f8b09039fd4e",
    "_uuid": "46f0b12d7bf66712642e9a9b807f5ef398426b83"
   },
   "outputs": [],
   "source": [
    "# 데이터 수집\n",
    "\n",
    "# 데이터 객체를 만들기 위해 pandas 임포트\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 분석 자료가 될 훈련 데이터셋, 시험 데이터셋 읽어오기\n",
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "836a454f-17bc-41a2-be69-cd86c6f3b584",
    "_uuid": "1ed3ad39ead93977b8936d9c96e6f6f806a8f9b3"
   },
   "source": [
    "## 3. Exploratory data analysis\n",
    "Printing first 5 rows of the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "749a3d70-394c-4d2c-999a-4d0567e39232",
    "_uuid": "b9fdb3b19d7a8f30cd0bb69ae434e04121ecba93"
   },
   "outputs": [],
   "source": [
    "# 데이터 분석\n",
    "\n",
    "# 훈련 데이터셋 확인 (80행) - 기본값 5행\n",
    "train.head(80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "- Survived: \t0 = No, 1 = Yes  \n",
    "- pclass: \tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd  \t\n",
    "- sibsp:\t# of siblings / spouses aboard the Titanic  \t\n",
    "- parch:\t# of parents / children aboard the Titanic  \t\n",
    "- ticket:\tTicket number\t\n",
    "- cabin:\tCabin number\t\n",
    "- embarked:\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5ebc1e0e-2b5a-4d92-98e0-defa019d4439",
    "_uuid": "1892fbb34b26d775d1c428fdb7b6254449286b28"
   },
   "source": [
    "**Total rows and columns**\n",
    "\n",
    "We can see that there are 891 rows and 12 columns in our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시험 데이터셋 확인 (5행: 기본값)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ed1e7849-d1b6-490d-b86b-9ca71dfafc7d",
    "_uuid": "5a641beccf0e555dfd7b9a53a17188ea6edef95b"
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터셋 행렬 확인 - 891행 12열\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시험 데이터셋 행렬 확인 - 418행 11열\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "418b8a69-f2aa-442d-8f45-fa8887190938",
    "_uuid": "4ee2591110660a4a16b3da7a7530f0945e121b46"
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터셋 정보 확인\n",
    "train.info()\n",
    "\n",
    "# 열이름, null 아닌 값 카운트, dataType이 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시험 데이터셋 정보 확인\n",
    "test.info()\n",
    "\n",
    "# 열이름, null 아닌 값 카운트, dataType이 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "abc3c4fc-6419-405f-927a-4214d2c73eec",
    "_uuid": "622d4d4b2ba8f77cc537af97fc343d4cd6de26b2"
   },
   "source": [
    "We can see that *Age* value is missing for many rows. \n",
    "\n",
    "Out of 891 rows, the *Age* value is present only in 714 rows.\n",
    "\n",
    "Similarly, *Cabin* values are also missing in many rows. Only 204 out of 891 rows have *Cabin* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0663e2bb-dc27-4187-94b1-ff4ff78b68bc",
    "_uuid": "3bf74de7f2483d622e41608f6017f2945639e4df"
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터셋에서 결측값을 가진 항이 열마다 몇개 있는지 확인\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시험 데이터셋에서 결측값을 가진 항이 열마다 몇개 있는지 확인\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "176aa52d-fde8-42e6-a3ee-db31f8b0ca49",
    "_uuid": "b48a9feff6004d783960aa1b32fdfde902d87e21"
   },
   "source": [
    "There are 177 rows with missing *Age*, 687 rows with missing *Cabin* and 2 rows with missing *Embarked* information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c8553d48-c5e0-4947-bd13-1b38509c850c",
    "_uuid": "1a28e607e9ed63cefe0f35a4e4d72f2f36299323"
   },
   "source": [
    "### import python lib for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1d8a6d2-c22d-435c-8c98-973e8f41b138",
    "_uuid": "26411c710f69b29939c815d5f5ab01d9177df7d0"
   },
   "outputs": [],
   "source": [
    "# 시각화를 위해 matplotlib.pyplot 가져오기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# matplot을 실행한 브라우저에서 바로 보여주기\n",
    "%matplotlib inline\n",
    "\n",
    "# matplotlib를 쉽게 사용하게 해주는 seaborn 가져오기\n",
    "import seaborn as sns\n",
    "#sns.set() # setting seaborn default for plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart for Categorical Features\n",
    "- Pclass\n",
    "- Sex\n",
    "- SibSp ( # of siblings and spouse)\n",
    "- Parch ( # of parents and children)\n",
    "- Embarked\n",
    "- Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart(feature):\n",
    "\t\t# 훈련데이터에서 입력인자 특성 열에서 생존자만 카운트해서 series 데이터로 반환\n",
    "    survived = train[train['Survived']==1][feature].value_counts()\n",
    "\n",
    "\t\t# 훈련데이터에서 입력인자 특성 열에서 사망자만 카운트해서 series 데이터로 반환\n",
    "    dead = train[train['Survived']==0][feature].value_counts()\n",
    "\n",
    "\t\t# 판다스 라이브러리로 생존자와 사망자 series 데이터를 데이터프레임으로 생성\n",
    "    df = pd.DataFrame([survived,dead])\n",
    "\n",
    "\t\t# 데이터프레임 인덱스 설정 [Servived, Dead] (행)\n",
    "    df.index = ['Survived','Dead']\n",
    "\n",
    "\t\t# 시각화 설정\n",
    "\t\t# 막대차트\n",
    "\t\t# 막대 분리하지 않고 하나로 누적시켜 그리기\n",
    "\t\t# 그래프 크기 가로 10인치 세로 5인치\n",
    "    df.plot(kind='bar', stacked=True, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성별 특성에 따른 생존자, 사망자 막대그래프\n",
    "bar_chart('Sex')\n",
    "\n",
    "# 여성이 남성보다 생존확률이 높다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chart confirms **Women** more likely survivied than **Men**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객실등급 특성에 따른 생존자, 사망자 막대그래프\n",
    "bar_chart('Pclass')\n",
    "\n",
    "# 1등급 객실에 탄 승객이 다른 등급객실에 탄 승객보다 생존확률이 높고\n",
    "# 3등급 객실에 탄 승객이 다른 등급객실에 탄 승객보다 사망확률이 높다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chart confirms **1st class** more likely survivied than **other classes**  \n",
    "The Chart confirms **3rd class** more likely dead than **other classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형제자매 또는 배우자와 같이 승선 특성에 따른 생존자, 사망자 막대그래프\n",
    "bar_chart('SibSp')\n",
    "\n",
    "# 2명이상의 형제자매나 배우자와 같이탄 승객이 생존확률이 높고\n",
    "# 형제자매나 배우자 없이 탄 승객은 사망확률이 높다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chart confirms **a person aboarded with more than 2 siblings or spouse** more likely survived  \n",
    "The Chart confirms ** a person aboarded without siblings or spouse** more likely dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부모, 자식과 같이 승선 특성에 따른 생존자, 사망자 막대그래프\n",
    "bar_chart('Parch')\n",
    "\n",
    "# 2명이상의 부모나 자식과 같이탄 승객이 생존확률이 높고\n",
    "# 부모나 자식없이 혼자탄 승객이 사망확률이 높다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chart confirms **a person aboarded with more than 2 parents or children** more likely survived  \n",
    "The Chart confirms ** a person aboarded alone** more likely dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 승선항구 특성에 따른 생존자, 사망자 막대그래프\n",
    "# S : Southampton 항구\n",
    "# C : Cherbourg 항구\n",
    "# Q : Queenstown 항구\n",
    "bar_chart('Embarked')\n",
    "\n",
    "# Cherbourg 항구에서 승선한 승객이 생존확률이 높고\n",
    "# Queenstown, Southamton 항구에서 승선한 승객이 사망확률이 높다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chart confirms **a person aboarded from C** slightly more likely survived  \n",
    "The Chart confirms **a person aboarded from Q** more likely dead  \n",
    "The Chart confirms **a person aboarded from S** more likely dead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "810cd964-24eb-44fb-9e7b-18bbddd4900f",
    "_uuid": "fd86ccdf2d1248b79c68365444e96e46a50f3f5a"
   },
   "source": [
    "## 4. Feature engineering\n",
    "\n",
    "Feature engineering is the process of using domain knowledge of the data  \n",
    "to create features (**feature vectors**) that make machine learning algorithms work.  \n",
    "\n",
    "feature vector is an n-dimensional vector of numerical features that represent some object.  \n",
    "Many algorithms in machine learning require a numerical representation of objects,  \n",
    "since such representations facilitate processing and statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터 처리\n",
    "\n",
    "# 훈련 데이터 보기\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 how titanic sank?\n",
    "sank from the bow of the ship where third class rooms located  \n",
    "conclusion, Pclass is key feature for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어떻게 타이타닉은 가라앉았나\n",
    "# 3등급 객실이 위치한 배의 활에서부터 가라앉기 시작함\n",
    "# 결론적으로 객실등급은 분류를 위한 주요한 특징\n",
    "\n",
    "# 이미지 로드\n",
    "Image(url= \"https://static1.squarespace.com/static/5006453fe4b09ef2252ba068/t/5090b249e4b047ba54dfd258/1351660113175/TItanic-Survival-Infographic.jpg?format=1500w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 보기 (10행)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 시험 데이터\n",
    "train_test_data = [train, test] # combining train and test dataset\n",
    "\n",
    "# 조합된 데이터 셋에서 이름 특성에서 '영문자(대소문자).'의 속성을 가진 문자열을 추출한다\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출한 훈련 데이터셋의 값이 각각 몇개있는지 카운트\n",
    "train['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출한 시험 데이터셋의 값이 각각 몇개있는지 카운트\n",
    "test['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title map\n",
    "Mr : 0  \n",
    "Miss : 1  \n",
    "Mrs: 2  \n",
    "Others: 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n",
    "                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n",
    "                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unnecessary feature from dataset\n",
    "train.drop('Name', axis=1, inplace=True)\n",
    "test.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Sex\n",
    "\n",
    "male: 0\n",
    "female: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_mapping = {\"male\": 0, \"female\": 1}\n",
    "for dataset in train_test_data:\n",
    "    dataset['Sex'] = dataset['Sex'].map(sex_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1 some age is missing\n",
    "Let's use Title's median age for missing Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing age with median age for each title (Mr, Mrs, Miss, Others)\n",
    "train[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\n",
    "test[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(30)\n",
    "train.groupby(\"Title\")[\"Age\"].transform(\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    " \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(20, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(30, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(40, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(40, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2 Binning\n",
    "Binning/Converting Numerical Age to Categorical Variable  \n",
    "\n",
    "feature vector map:  \n",
    "child: 0  \n",
    "young: 1  \n",
    "adult: 2  \n",
    "mid-age: 3  \n",
    "senior: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\n",
    "Pclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\n",
    "Pclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\n",
    "df = pd.DataFrame([Pclass1, Pclass2, Pclass3])\n",
    "df.index = ['1st class','2nd class', '3rd class']\n",
    "df.plot(kind='bar',stacked=True, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more than 50% of 1st class are from S embark  \n",
    "more than 50% of 2nd class are from S embark  \n",
    "more than 50% of 3rd class are from S embark\n",
    "\n",
    "**fill out missing embark with S embark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "for dataset in train_test_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing Fare with median fare for each Pclass\n",
    "train[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\n",
    "test[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\n",
    "train.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',shade= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()\n",
    " \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',shade= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',shade= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',shade= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2\n",
    "    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Cabin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].str[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\n",
    "Pclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\n",
    "Pclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\n",
    "df = pd.DataFrame([Pclass1, Pclass2, Pclass3])\n",
    "df.index = ['1st class','2nd class', '3rd class']\n",
    "df.plot(kind='bar',stacked=True, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\n",
    "for dataset in train_test_data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing Fare with median fare for each Pclass\n",
    "train[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\n",
    "test[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 FamilySize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\n",
    "test[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'FamilySize',shade= True)\n",
    "facet.set(xlim=(0, train['FamilySize'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\n",
    "for dataset in train_test_data:\n",
    "    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_drop = ['Ticket', 'SibSp', 'Parch']\n",
    "train = train.drop(features_drop, axis=1)\n",
    "test = test.drop(features_drop, axis=1)\n",
    "train = train.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.drop('Survived', axis=1)\n",
    "target = train['Survived']\n",
    "\n",
    "train_data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Classifier Modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Cross Validation (K-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 13)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Ramdom Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=13)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.5 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.mean(score)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "clf.fit(train_data, target)\n",
    "\n",
    "test_data = test.drop(\"PassengerId\", axis=1).copy()\n",
    "prediction = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": prediction\n",
    "    })\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "This notebook is created by learning from the following notebooks:\n",
    "\n",
    "- [Mukesh ChapagainTitanic Solution: A Beginner's Guide](https://www.kaggle.com/chapagain/titanic-solution-a-beginner-s-guide?scriptVersionId=1473689)\n",
    "- [How to score 0.8134 in Titanic Kaggle Challenge](http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html)\n",
    "- [Titanic: factors to survive](https://olegleyz.github.io/titanic_factors.html)\n",
    "- [Titanic Survivors Dataset and Data Wrangling](http://www.codeastar.com/data-wrangling/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
